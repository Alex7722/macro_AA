---
title: "DHM: a Digital History of Macroeconomics interactive platform"
short: "Digital History of Macroeconomics"
journal: "JEL" # AER, AEJ, PP, JEL
month: "`r format(Sys.Date(), '%m')`"
year: "`r format(Sys.Date(), '%Y')`"
vol: 1
issue: 1
jel:
  - A10
  - A11
keywords:
  - first keyword
  - second keyword
author:
  - name: Aurélien Goutsmedt
    firstname: Aurélien
    surname: Goutsmedt
    email: Goutsmedt@example.com
    affiliation: ULC
  - name: Alexandre Truc
    firstname: Alexandre
    surname: Truc
    email: Alexandre.Truc@unice.fr
    affiliation: UCA (Université Côte d'Azur), CNRS (Centre national de la recherche scientifique), GREDEG (Groupe de Recherche en Droit, Economie, Gestion), 250 Rue Albert Einstein, 06560 Valbonne. France.
acknowledgements: |
  We thank Till Duppe for his wisdom
abstract: |
  Abstract goes here
output: rticles::aea_article
bibliography: references.bib
---

The Mapping Macroeconomics project is an online interactive platform displaying bibliometric data on a large set of macroeconomic articles. It aims at offering a better understanding of the history of macroeconomics through the navigation between the different bibliometric networks.

The point of departure of the project is the observation of an exponential increase in the number of articles published in academic journals in economics since the 1970s. This phenomenon makes it harder for historians of economics to properly assess the trends in the transformation of economics, the main topics researched, the most influential authors and ideas, etc. We consider that developing collective quantitative tools could help historians to confront this challenge. The opportunities that a quantitative history brings are particularly useful to the recent history of macroeconomics. Practicing macroeconomists are eager to tell narratives of the evolution of their field that serve the purpose of intervening on current debates, by giving credit to particular authors and weight to specific ideas. Historians who go into this area find plenty of accounts by macroeconomists and have to handle the vast increase in the macroeconomic literature since the last quarter of the past century. The Mapping Macroeconomics platform aims at helping historians to empirically check macroeconomists' narratives on the discipline, to explore interesting patterns on the evolution of macroeconomics, and eventually to write new histories of macroeconomics.

\section{Methodology}

\subsection{Construction of the Corpus}

Our corpus is composed of macroeconomic articles published in economics. We identified all articles published in macroeconomics using JEL codes related to macroeconomics (Econlit database). JEL codes are used in economics to classify articles into specialties, like "Microeconomics", "Macroeconomics & Monetary Economics", "Industrial Organization", etc. An article can have multiple JEL codes and so can be identified as part of multiple specialties. The JEL nomenclature was radically altered in 1991, and while these results in some discontinuity between the two nomenclatures, there are some correspondence (see @cherrierClassifyingEconomicsHistory2017 for a history of the JEL codes). The contemporary list of JEL codes can be found on the AEA website[^1] and the old JEL codes with old/new correspondence table can be found in the Journal of Economic Literature, volume 29(1) (JEL, 1991).[^2]

[^1]: <https://www.aeaweb.org/econlit/jelCodes.php>

[^2]: <https://www.aeaweb.org/econlit/jelCodes.php>

For our corpus, we consider that an article is a macroeconomics article if it has one of the following codes:

-   For old JEL codes (pre-1991): 023, 131, 132, 133, 134, 223, 311, 313, 321, 431, 813, 824.

-   For new JEL codes (1991 onward): all E, F3 and F4.2.

Two additional comments on the JEL classification are necessary:

-   First, we had to use some pre-1991 JEL codes that are not considered in the new classification as totally belonging to macroeconomics. Consequently, many articles in our pre-1991 corpus are public finance/public economics articles. Nonetheless, this group is clearly identifiable in our networks and thus do not disturb the interpretation of our results.

-   Second, in the recent classification, the letter E designates macroeconomics JEL code, while F designates International Economics. In this last sub-discipline, we decided that it would be important to have articles dealing with international macroeconomics and thus we integrated articles with F3 and F4.2 JEL codes.

Using these JEL codes, we match the articles extracted from Econlit with Web of Science articles using the following set of matching variables:

-   Journal, Volume, First Page

-   Year, Journal, First Page, Last Page

-   First Author, Year, Volume, First Page

-   First Author, Title, Year

-   Title, Year, First Page

We expect that these matching procedure results in some false positive. However, two elements prevent false positive from having any importance on the platform. First, we applied a general threshold on edges by keeping links between articles that had at least two references in common, and our projected networks are only made of the main component of our corpus (i.e,the biggest connected network). In other words, false positive have a very high chance of being completely disconnected from our main component and therefore filtered out from our analysis. Second, even if false positive "articles" are present in some networks, these articles, when irrelevant, would be relegated at the margins of our networks and thus do not have any significant impact on our results.

\subsection{Network construction}

Our networks are based on bibliographic coupling. In a bibliographic coupling network, a link is created between two articles when they have one or more references in common. The more references two articles have in common, the stronger the link. The idea is that articles sharing many references to gather are likely to share cognitive content (ideas, theories, methods, objects of study, etc.).

To normalize and weight the link between two articles, we used the refined bibliographic coupling strength of @shenRefinedMethodComputing2019. This method normalized and weight the strength between articles by considering two important elements:

1.  The size of the bibliography of the two linked articles. It means that common references between two articles with long bibliography are weighted as less significant since the likeliness of potential common references is higher. Conversely, common references between two articles with a short bibliography is weighted as more significant.

2.  The number of occurrences of each reference in the overall corpus. When a reference is shared between two articles, it is weighted as less significant if it is a very common reference across the entire corpus and very significant if it is scarcely cited. The assumption is that a very rare common reference points to a higher content similarity between two articles than a highly cited reference.

For all macroeconomics articles published in the EER and in the Top 5, we build successive networks on 5-year overlapping windows (1969-1973; 1970-1974; ...; 2010-2014; 2011-2015). This results in 43 networks.

For each network, we apply a variety of treatments:

-   We apply a general threshold on edges by removing links between articles that had only two references in common before weighting. We consider that it is more likely that the link between two articles is significant if they share at least two references. This is a great way to filter very common references such as econometrics hand book that might link two articles that have little in common. This is also a way to filter potential false positive from our matching method and exclude article that have little in common with the overall network beside one reference.[^3]

-   We only kept the main component of the network (thus ignoring singleton and secondary components). Nonetheless, we made sure that no other components represented more than 2% of the whole network.

-   We place nodes in a 2-dimensional space using the Force Atlas 2 algorithm [@jacomy_ForceAtlas2ContinuousGraph_2014]. Force Atlas relied on an attractive force - bringing closer articles which are linked - and a repulsive force - moving away the articles with no link, while minimizing the crossing between edges.

-   The size of the nodes depends on the number of citations - coming from other macroeconomics papers - the article received during the time window.

-   We identify relevant groups of articles using a cluster detection algorithm and colored nodes according to the cluster they belong to (see below for details).

[^3]: There exists other recently developed methods to filter non-significant edges such as the Stochastic Degree Sequence Model from backbone approaches [@domagalskiBackbone2021]. In addition to being costly computationally and unpractical in our case, backbone approaches are better suited for tightly knit networks for which there is not obvious weighting methods. This is not the case for your corpus. With a low threshold and the weighting method used, clear and stable clusters are easily identified.

\subsection{Cluster detection}

We use the Leiden detection algorithm [@traag_LouvainLeidenGuaranteeing_2019] that optimize the modularity on each network to identify groups of articles that are similar to each other and dissimilar to the rest of the network. We use a resolution of 1 with 1000 iterations. This results in X clusters across all networks.

Because networks have a lot of overlaps (three years are common to successive networks), many clusters between two successive periods are composed of the same articles. To identify these clusters that are very similar between two successive time-windows, we consider that two clusters can be merged if (i) at least 51% of the articles in a cluster of the first time-window were in the same cluster in the second time window and (ii) the cluster was also composed by at least 51% of articles of the first time-window. Simply put, between two successive time-windows, if two clusters share a high number of articles, and are both mostly composed by these shared articles, they are considered the same cluster.

Finally, we collect a certain number of information for each cluster (most cited nodes, most cited references, recurrent authors and journals, most "identifying" words in title) to name the clusters. We use two-level names:

-   Meta-names are names shared across different clusters. They capture a broader characterization of the clusters: Business Cycles; Consumption, Investment & Production; Econometrics; Growth; International Macroeconomics; Keynesian Economics, Macro Policy; Monetary & Financial Economics; Public Finance.

-   Sub-names are unique to clusters. They capture what makes the cluster specific to other clusters in the network, and other clusters with the same meta-name (e.g., International Macroeconomics: Exchange Rate Dynamics).

\section{Features}

\subsection{Graph exploration and manual search}

The platform and its results rely on data taken from Web of Science. Besides the underlying data used, we can distinguish two analytical layers to the platform. The first layer is made of the network nodes and edges and capture the way we project bibliographic information on the a two-dimensional space.

The main methodological elements that characterize this layers is the method of projection of the bipartite graph used (bibliographic coupling), the length of the time-window, the edge threshold, the filtering of nodes unconnected to the main component, the way we weighted the edges, and finally the algorithm used to placed nodes in a two-dimensional space.

User of the platform can explore this first analytical layer freely using the main view of the platform. Using the timeline at the bottom of the platform, a particular time window can be chosen to display all macroeconomics articles published during that time frame.

A first obvious way to explore this graphical representation of the literature is to use the mouse to move (sustained click), zoom (mouse scroll), and interact with the network (left click). Different level of zoom capture different information. Being completely zoomed out, user can get an overview of the network, spot some groups of nodes visually, and get the title of the most cited articles in the network of the time window.

Example 1969-1973: very obvious cluster such as public finance, less obvious cluster such as a detached group of article about the Cambridge controversy.

Biggest node example: find during a particular time frame, which articles recently published generated a lot of attention =\> follow the attention over long term

By zooming in, it is can focus on particular subset of the network. As the network is zoomed in, you can

Neighborhood. Click on a node.

Example of Marxist article

This exploratory tool can be pushed further using algorithmic detected clusters.

\subsection{Clusters analysis}

Sample figure:

```{=tex}
\begin{figure}
Figure here.

\caption{Caption for figure below.}
\begin{figurenotes}
Figure notes without optional leadin.
\end{figurenotes}
\begin{figurenotes}[Source]
Figure notes with optional leadin (Source, in this case).
\end{figurenotes}
\end{figure}
```
Sample table:

```{=tex}
\begin{table}
\caption{Caption for table above.}

\begin{tabular}{lll}
& Heading 1 & Heading 2 \\
Row 1 & 1 & 2 \\
Row 2 & 3 & 4%
\end{tabular}
\begin{tablenotes}
Table notes environment without optional leadin.
\end{tablenotes}
\begin{tablenotes}[Source]
Table notes environment with optional leadin (Source, in this case).
\end{tablenotes}
\end{table}
```
\% The appendix command is issued once, prior to all appendices, if any. \appendix

\section{Mathematical Appendix}
