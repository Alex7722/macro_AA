---
title: "EER Corpus Dashboard"
author: "Aur√©lien Goutsmedt and Alexandre Truc"
date: "Last compiled on `r format(Sys.Date())`"
output: 
  flexdashboard::flex_dashboard:
    vertical_layout: scroll
    orientation: rows
    always_allow_html: yes

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, eval = TRUE, include = TRUE)
```

```{css zoom-lib-src, echo = FALSE}
# Follows the css and js script used for allow zooming in graphs
script src = "https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"
```

```{js zoom-jquery, echo = FALSE}
 $(document).ready(function() {
    $('body').prepend('<div class=\"zoomDiv\"><img src=\"\" class=\"zoomImg\"></div>');
    // onClick function for all plots (img's)
    $('img:not(.zoomImg)').click(function() {
      $('.zoomImg').attr('src', $(this).attr('src')).css({width: '100%'});
      $('.zoomDiv').css({opacity: '1', width: 'auto', border: '1px solid white', borderRadius: '5px', position: 'fixed', top: '50%', left: '50%', marginRight: '-50%', transform: 'translate(-50%, -50%)', boxShadow: '0px 0px 50px #888888', zIndex: '50', overflow: 'auto', maxHeight: '100%'});
    });
    // onClick function for zoomImg
    $('img.zoomImg').click(function() {
      $('.zoomDiv').css({opacity: '0', width: '0%'}); 
    });
  });
```

```{r source-and-packages, eval = TRUE}
library(flexdashboard)
source("~/macro_AA/EER_Paper/Script_paths_and_basic_objects_EER.R")
source("~/macro_AA/functions/functions_for_network_analysis.R")

generate_png = FALSE # choosing if you want to recreate the png of the different graphs or just use those already created

institutions <- readRDS(paste0(data_path,"EER/1_Corpus_Prepped_and_Merged/Institutions_cleaned.rds")) %>% data.table
list_graph <- readRDS(paste0(data_path,"EER/2_Raw_Networks_and_Alluv/list_networks.rds"))
Corpus <- readRDS(paste0(data_path,"EER/1_Corpus_Prepped_and_Merged/Corpus.rds"))
Authors <- readRDS(paste0(data_path,"EER/1_Corpus_Prepped_and_Merged/Authors.rds"))
Refs <- readRDS(paste0(data_path,"EER/1_Corpus_Prepped_and_Merged/Refs.rds")) %>% 
  mutate(Titre = toupper(Titre)) %>% 
  as.data.table()
alluv_dt <- readRDS(paste0(data_path,"EER/2_Raw_Networks_and_Alluv/alluv_dt.rds"))
alluv_with_abstract <- merge(alluv_dt, Corpus[, c("Id","abstract")], by = "Id") %>% 
  .[share_leiden_max >=0.05 & n_years >= 3] %>%
  unite("words", Titre, abstract, sep = " ")
alluv_dt <- alluv_dt[share_leiden_max >=0.05][,c("Leiden1","Window","Id")]

```

```{r prepare-data, eval = TRUE}

list_graph <- lapply(list_graph, function(tbl)(tbl %>% activate(nodes) %>% mutate(size = replace(size, size == 0, 1))))
list_graph <- lapply(list_graph, function(tbl) (tbl %>% activate(nodes) %>% mutate(x = rescale(x, to = c(0,1000)), y = rescale(y, to = c(0,1000)))))

# creating a table with the data for nodes and edges for each window

nodes_lf <- lapply(list_graph, function(tbl) (tbl %>% activate(nodes) %>% as.data.table()))
nodes_lf <- lapply(nodes_lf, function(dt) (dt[, .(ID_Art, x, y, size, Label, Titre, Nom_ISI)]))
nodes_lf <- rbindlist(nodes_lf, idcol = "window")
nodes <- merge(nodes_lf, alluv_dt, by.x = c("ID_Art","window"), by.y = c("Id","Window"), all.x = TRUE) 

nodes <- nodes[, window := paste0(window, "-", as.integer(window) + (time_window-1))][order(ID_Art, window)]

nodes <- nodes %>% 
  mutate(Leiden1 = replace(Leiden1, is.na(Leiden1), "small communities"))

color <- c("#808080",scico(n = length(unique(nodes$Leiden1)) - 1, palette = "roma") %>% 
  sample())

nodes$Leiden1 <- factor(nodes$Leiden1, levels = c(unique(nodes[Leiden1 == "small communities"]$Leiden1), unique(nodes[Leiden1 != "small communities"]$Leiden1)))
```

# Information on the EER corpus

Graphs EER networks timeline {data-height=950}
-------------------------------------

### Evolution of the networks and the communities over time

```{r graphs-network-timeline, eval = TRUE}
plot_ly(nodes, 
        x = ~x, 
        y = ~y,
        type = "scatter",
        mode = "markers",
        text = ~paste('</br>', Label,
                      '</br>', str_wrap(Titre, width = 30),
                      '</br> Community:', Leiden1),
        hoverinfo = "text",
        size = ~log(size),
        sizes = c(30,300),
        frame = ~window,
        ids = ~ID_Art,
        color = ~Leiden1,
        colors = color,
        showlegend = TRUE) %>% 
  add_trace(alpha = 0.8) %>% 
  layout(yaxis = list(zeroline = FALSE,
                      showgrid = FALSE),
         xaxis = list(zeroline = FALSE,
                      showgrid = FALSE)) %>% 
  config(scrollZoom = TRUE) %>% 
  # highlight(on = "plotly_selected", 
  #          selectize = TRUE, 
  #         persistent = TRUE) %>% 
  animation_opts(frame = 2000,
                 transition = 1000,
                 redraw = TRUE,
                 mode = "next") 

```

Graphs & Table EER corpus {.tabset .tabset-pill data-height=850} 
-------------------------------------

### Most recurrent affiliations

```{r top_inst, eval = TRUE, include = TRUE, fig.height= 12}

big_inst_year <- institutions[, `:=` (n = .N), by = "Annee_Bibliographique"] %>% 
  .[Institution != "NULL", frequency := round(.N/n,2), by = c("Annee_Bibliographique","Institution")] %>% 
  select(Institution,Annee_Bibliographique,frequency,Type) %>% 
  filter(Annee_Bibliographique > 1971) %>% # We have some missing data for 1970 and 1971 for now
  mutate(Annee_Bibliographique = as.numeric(Annee_Bibliographique)) %>%  # useful for plotting later
  unique()

big_inst <- big_inst_year %>% 
  group_by(Annee_Bibliographique) %>% 
  arrange(Annee_Bibliographique,desc(frequency)) %>% 
  slice(1:2) %>% 
  select(Institution) %>% 
  unique()

big_inst_year <- big_inst_year %>% 
  filter(Institution %in% big_inst$Institution)

ref_table <- data.table("Institution" = rep(unique(big_inst_year$Institution), length(1971:2019)), "Annee_Bibliographique" = rep(1971:2019, each = length(unique(big_inst_year$Institution))))
big_inst_year <- merge(big_inst_year, ref_table, by = c("Institution","Annee_Bibliographique"), all.y = TRUE) %>% 
  mutate(frequency = replace(frequency, is.na(frequency), 0))
big_inst_year <- merge(big_inst_year[,c("Institution","Annee_Bibliographique","frequency")], unique(big_inst_year[!is.na(Type),c("Institution","Type")]), by = "Institution", all.x = TRUE)

big_inst_year <- highlight_key(big_inst_year, ~Type)
#type_filter <- filter_select(
#  "Type", "Type of Institution", 
#  big_inst_year, ~Type
#)

x <- ggplot(big_inst_year, aes(Annee_Bibliographique, frequency, color = Institution)) +
#  geom_point() +
  geom_smooth(se = FALSE, span = 0.3, size = 1.5, alpha = 0.6) +
  scale_color_scico_d(palette = "roma") +
  theme_classic()

#bscols(type_filter, highlight(ggplotly(x), "plotly_click"), widths = c(6,6))

type_inst <- institutions[, `:=` (n = .N), by = "Annee_Bibliographique"] %>% 
  .[Institution != "NULL", frequency := round(.N/n,2), by = c("Annee_Bibliographique","Type")] %>% 
  select(Annee_Bibliographique,frequency,Type) %>% 
  filter(Annee_Bibliographique > 1971 & !is.na(Type) & Type != "NA") %>% # We have some missing data for 1970 and 1971 for now
  mutate(Annee_Bibliographique = as.numeric(Annee_Bibliographique)) %>%  # useful for plotting later
  unique()

ref_table <- data.table("Type" = rep(unique(type_inst$Type), length(1971:2019)), "Annee_Bibliographique" = rep(1971:2019, each = length(unique(type_inst$Type))))
type_inst <- merge(type_inst, ref_table, by = c("Type","Annee_Bibliographique"), all.y = TRUE) %>% 
  mutate(frequency = replace(frequency, is.na(frequency), 0))

type_inst <- highlight_key(type_inst, ~Type)

y <- ggplot(type_inst, aes(Annee_Bibliographique, frequency, color = Type)) +
#  geom_point() +
  geom_smooth(se = FALSE, span = 0.3, size = 1.5, alpha = 0.6, show.legend = FALSE) +
  scale_color_scico_d(palette = "vik", begin = 0.1) +
  theme_classic()

#ggplotly(y)

subplot(style(highlight(ggplotly(y), "plotly_click"), showlegend = FALSE),highlight(ggplotly(x), "plotly_click"), nrows = 2)
```

### Authors' country affiliation

```{r top_country-1, eval = TRUE}
# We calculate here the share of authors for the biggest countries

count_year <- institutions[,n_inst_tot:=.N, Pays][order(-n_inst_tot)]
count_year <- count_year[n_inst_tot<200, Pays:="OTHER"]
count_year <- count_year[, nb_aut_country:=.N, .(Annee_Bibliographique, Pays)]
count_year <- count_year %>% 
  mutate(Annee_Bibliographique = as.numeric(Annee_Bibliographique),
         Pays = fct_rev(fct_infreq(Pays)))

count_year <- highlight_key(count_year, ~Countries_grouped)
x <- ggplot(count_year, aes(Annee_Bibliographique, after_stat(count), fill = Pays)) +
  geom_density(position = "fill") +
  labs(fill = "Countries (Top 7)") +
  scale_x_continuous("Years") +
  scale_y_continuous("Countries Identified by Unique Institution by Paper") +
  scale_fill_scico_d(palette = "hawaii", end = 1, direction = 1) +
  theme_classic()

# We calculate here the share of authors for different grouped countries (EUROPE, USA and OTHER)
count_year_group <- institutions[,n_inst_tot:=.N, Countries_grouped][order(-n_inst_tot)]
count_year_group <- count_year_group[n_inst_tot<300, Countries_grouped:="OTHER"]
count_year_group <- count_year_group[, nb_aut_country:=.N, .(Annee_Bibliographique, Countries_grouped)]
count_year_group <- count_year_group %>% 
  mutate(Annee_Bibliographique = as.numeric(Annee_Bibliographique),
         Countries_grouped = fct_rev(fct_infreq(Countries_grouped)))

count_year_group <- highlight_key(count_year_group, ~Countries_grouped)
y <- ggplot(count_year_group, aes(Annee_Bibliographique, after_stat(count), fill = Countries_grouped)) +
  geom_density(position = "fill") +
  labs(fill = "Countries (Grouped)") +
  scale_x_continuous("Years") +
  scale_y_continuous("Countries Identified by Unique Institution by Paper") +
  scale_fill_scico_d(palette = "lapaz", end = 0.9, direction = -1) +
  theme_classic()

subplot(highlight(ggplotly(y), "plotly_click"),highlight(ggplotly(x), "plotly_click"))

```

### Most cited references

```{r references, eval = TRUE}

top_auth <- Authors[,.N,Nom_ISI] %>% slice_max(order_by = N, n = 20)

top_ref <- copy(Refs[ItemID_Ref_Target != "NULL" & ItemID_Ref_Target != "0", nb_cit := .N, by = "ItemID_Ref_Target"][order(-nb_cit), head(.SD, 1), .(ItemID_Ref_Target)][,.(Nom, Titre, Annee_Bibliographique_Target,ItemID_Ref_Target,nb_cit)]%>% slice_max(order_by = nb_cit, n = 20))

top_ref_alt <- merge(Refs[ItemID_Ref_Target != "NULL" & ItemID_Ref_Target != 0], Corpus[, c("ID_Art","Annee_Bibliographique")], by.x = "ID_Art_Source", by.y = "ID_Art") 
top_ref_alt <- top_ref_alt[, nb_cit_year := .N, by = "Annee_Bibliographique"][,nb_cit_year := 1/nb_cit_year][, nb_cit_weighted := sum(nb_cit_year), by = "ItemID_Ref_Target"]
top_ref_alt <- top_ref_alt[order(-nb_cit_weighted), head(.SD, 1), .(ItemID_Ref_Target)][,.(Nom, Titre, Annee_Bibliographique_Target,ItemID_Ref_Target,nb_cit_weighted)] %>% 
  slice_max(order_by = nb_cit_weighted, n = 20)

top_ref <- merge(top_ref, top_ref_alt, by = "ItemID_Ref_Target", all = TRUE)
top_ref[is.na(Nom.x)]$Nom.x <- top_ref[is.na(Nom.x)]$Nom.y
top_ref[is.na(Annee_Bibliographique_Target.x)]$Annee_Bibliographique_Target.x <- top_ref[is.na(Annee_Bibliographique_Target.x)]$Annee_Bibliographique_Target.y
top_ref[is.na(Titre.x)]$Titre.x <- top_ref[is.na(Titre.x)]$Titre.y
setnames(top_ref, c("Nom.x","Annee_Bibliographique_Target.x","Titre.x"), c("Nom","Annee_Bibliographique","Titre"))

bscols(widths = c(4,8),
       datatable(top_auth, extensions="Scroller", width="100%", class = "compact",
            options=list(deferRender=TRUE, scrollY=500, scroller=TRUE)),
       datatable(top_ref[, c("Nom","Annee_Bibliographique","Titre","nb_cit","nb_cit_weighted")], extensions="Scroller", width="100%", class = "compact",
            options=list(deferRender=TRUE, scrollY=500, scroller=TRUE))
)


```

### Important refs over time

```{r,eval=TRUE}
ref_over_time <- merge(unique(nodes_lf[,c("ID_Art","window")]), Refs[,c("ID_Art_Source","ItemID_Ref_Target","Label_Target","Titre","Revue")], by.x = "ID_Art", by.y = "ID_Art_Source", allow.cartesian = TRUE)
#ref_over_time <- merge(ref_over_time, unique(Corpus[JEL_id == 1,c("ID_Art")]), by = "ID_Art")

ref_over_time <- ref_over_time[, nb_ref := .N, by = "window"] %>% 
  .[, nb_cit := round((.N/nb_ref)*100,3), by = c("window","ItemID_Ref_Target")] %>% 
  .[, -"ID_Art"] %>% 
  .[order(window,nb_cit)] %>% 
  .[, head(.SD,1), by = c("window","ItemID_Ref_Target")]

top_ref <- ref_over_time %>% 
  filter(ItemID_Ref_Target != "NULL") %>%
  group_by(window) %>% 
  slice_max(nb_cit, n = 2, with_ties = TRUE) %>% 
  ungroup() %>% 
  select(-window, -nb_cit, -nb_ref) %>% 
  unique()

ref_over_time <- ref_over_time[ItemID_Ref_Target %in% top_ref$ItemID_Ref_Target] %>% 
  complete(ItemID_Ref_Target, window, fill = list(nb_cit = 0)) %>% 
  select(ItemID_Ref_Target, window, nb_cit) %>% 
  left_join(top_ref)

ref_over_time <- highlight_key(ref_over_time, ~Label_Target)
plot_ly(ref_over_time, 
        text = ~paste('</br>', Label_Target,
                      '</br>', str_wrap(Titre, width = 30),
                      '</br>', Revue),
        hoverinfo = "text") %>% 
  add_lines(x = ~window, 
        y = ~nb_cit,
        color = ~Label_Target) %>% 
  add_trace(alpha = 0.8) %>% 
  config(scrollZoom = TRUE) %>% 
  highlight(on = "plotly_click",
            persistent = TRUE,
            selectize = TRUE)

```

### Most recurrent words

```{r words, eval = TRUE}
words_over_time <- alluv_with_abstract %>%
  select(Id, Window, words) %>% 
  unique() %>% 
  unnest_tokens(word, words) %>% 
  anti_join(stop_words) %>% 
  as.data.table()

words_over_time <- words_over_time[, word := textstem::lemmatize_words(word)] %>% 
  .[, total_window := .N, by = "Window"] %>% 
  .[, proportion := round(.N/total_window,5), by = c("Window","word")] %>% 
  .[, -"Id"] %>% 
  .[order(Window,-proportion)]%>% 
  .[, head(.SD,1), by = c("Window","word")]

too_common_words <- c("economy",
                      "model",
                      "result",
                      "paper",
                      "country",
                      "price",
                      "function",
                      "effect",
                      "rate",
                      "increase",
                      "estimate",
                      "datum",
                      "evidence",
                      "level",
                      "study")
words_over_time <- words_over_time[! word %in% too_common_words]
  
top_word <- words_over_time %>% 
  group_by(Window) %>% 
  slice_max(proportion, n = 5, with_ties = TRUE) %>% 
  ungroup() %>% 
  select(-Window, -total_window, -proportion) %>% 
  unique()

words_over_time <- words_over_time[word %in% top_word$word] %>% 
  complete(word, Window, fill = list(proportion = 0)) %>% 
  select(word, Window, proportion) %>% 
  left_join(top_word)

plot_ly(words_over_time, 
        text = ~word,
        hoverinfo = "text") %>% 
  add_lines(x = ~Window, 
        y = ~proportion,
        color = ~word) %>% 
  add_trace(alpha = 0.8) %>% 
  config(scrollZoom = TRUE)

```


# Window-network information

network png {.tabset .tabset-pill .tabset-fade data-height=1100}
-------------------------------------

```{r ggraph-png, include = TRUE, eval = generate_png, results='asis'}
# adding window value directly within graphs
for(i in seq_along(list_graph)){
list_graph[[i]] <- list_graph[[i]] %>% activate(nodes) %>% mutate(window = paste0(names(list_graph[i]),"-",as.integer(names(list_graph[i])) + (time_window-1)))
}

color_com <- data.table("Leiden1" = levels(nodes$Leiden1),"color" = color)
color_com <- merge(nodes[,c("Leiden1","ID_Art","window")], color_com, by = "Leiden1")
color_com[color == "gray"]$color <- "#808080"

for(i in seq_along(list_graph)){
list_graph[[i]] <- list_graph[[i]] %>% activate(nodes) %>% left_join(color_com[window == unique(color_com[order(window)]$window)[i]])
list_graph[[i]] <- list_graph[[i]] %>% activate(nodes) %>% mutate(color = replace(color, is.na(color), "#808080"))

com_label <- label_com(list_graph[[i]], biggest_community = TRUE, community_threshold = 0.02, community_size_column = "share_leiden", community_name_column = "Leiden1")

x <- ggraph(list_graph[[i]], "manual", x = x, y = y) + 
  geom_edge_arc(aes(width = weight, color = node1.color), alpha = 0.4, strength = 0.2, show.legend = FALSE) +
  scale_edge_color_identity() +
  scale_edge_width_continuous(range = c(0.1,2)) +
  geom_point(aes(x = x, y = y, size = size, fill = color), pch = 21, alpha = 0.9, show.legend = FALSE) +
  scale_size_continuous(range = c(0.5,5)) +
  scale_fill_identity() +
  new_scale("size") +
  geom_label_repel(data = com_label, aes(x = x, y = y, label = Community_name, fill = color, size = Size_com), fontface = "bold", alpha = 0.9, point.padding = NA, show.legend = FALSE) +
  scale_size_continuous(range = c(0.5,5)) +
  new_scale_fill() +
  scale_fill_identity() +
  theme_void() +
  ggsave(paste0(picture_path,"graph_", unique(V(list_graph[[i]])$window),".png"), height = 8, width = 11, units = "cm")
}
```


```{r include-graph, eval = TRUE, include = TRUE, results = "asis"}
#picture_path <- "/home/aurelien/macro_AA/EER_Paper/Pictures/"
for(i in unique(nodes[order(window)]$window)){
  cat(sprintf("  \n### %s \n\n", i))
  cat('\n', '<br>', '\n\n')
  
  cat(paste0("<div style=\"width:100px; height:80px; text-align:center\">\n![](", picture_path, "graph_", i,".png)\n</div>"), "\n")
}
```

Tables & graphs per network {.tabset .tabset-pill .tabset-fade data-height=600}
-------------------------------------

### Most recurrent institutions and countries

```{r institutions, eval = TRUE}
inst_by_window <- merge(nodes_lf[, c("ID_Art","window")],
                      institutions[, ID_Art := as.character(ID_Art)][, c("ID_Art","Institution","Pays")], 
                      by = "ID_Art", allow.cartesian = TRUE)

inst_by_window[, window := paste0(window, "-", as.integer(window) + 6)]

inst_by_window[, `:=` (n = .N), by = "window"] %>% 
  .[Institution != "NULL", n_inst := round(.N/n,2), by = c("window","Institution")] %>% 
  .[Pays != "NULL", n_country := round(.N/n,2), by = c("window","Pays")] 

n_inst <- inst_by_window %>% 
  select(Institution,window,n_inst) %>% 
  unique() %>% 
  group_by(window) %>% 
  arrange(window,desc(n_inst)) %>% 
  top_n(5) %>% 
  mutate(type = "Institution") %>% 
  rename("entity" = Institution,
         "frequency" = n_inst)

n_country <- inst_by_window %>% 
  select(Pays,window,n_country) %>% 
  unique() %>% 
  group_by(window) %>% 
  arrange(window, desc(n_country)) %>% 
  top_n(5) %>% 
  mutate(type = "Country") %>% 
  rename("entity" = Pays,
         "frequency" = n_country)

inst_by_window <- rbind(n_inst,n_country) %>% as.data.table()

# Wrap data frame in SharedData
sd <- SharedData$new(inst_by_window)

# Create a filter input
bscols(widths = c(3,NA),
  list(filter_select("window", "Window", sd, ~window),
  filter_select("type", "Institution or Country", sd, ~type),
  filter_select("entity", "Institution or Country Name", sd, ~entity),
  filter_slider("frequency","Share over all affiliations", sd, ~frequency)),
  datatable(sd, extensions="Scroller", width="100%", class = "compact",
            options=list(deferRender=TRUE, scrollY=500, scroller=TRUE))
)

```

### Best refs per window

```{r refs-per-window, eval = TRUE}
ref_over_time <- merge(unique(nodes_lf[,c("ID_Art","window")]), Refs[,c("ID_Art_Source","ItemID_Ref_Target","Label_Target","Titre","Revue")], by.x = "ID_Art", by.y = "ID_Art_Source", allow.cartesian = TRUE)

ref_over_time <- ref_over_time[, nb_ref := .N, by = "window"] %>% 
  .[, nb_cit := round((.N/nb_ref)*100,3), by = c("window","ItemID_Ref_Target")] %>% 
  .[, -"ID_Art"] %>% 
  .[order(window,nb_cit)] %>% 
  .[, head(.SD,1), by = c("window","ItemID_Ref_Target")]

top_ref <- ref_over_time %>% 
  filter(ItemID_Ref_Target != "NULL") %>%
  group_by(window) %>% 
  slice_max(nb_cit, n = 10, with_ties = TRUE) %>% 
  mutate(window = paste0(window, "-",as.integer(window) + (time_window - 1))) %>% 
  unique() %>% 
  select(-ItemID_Ref_Target, -nb_ref)

# Wrap data frame in SharedData
sd <- SharedData$new(top_ref)

# Create a filter input
bscols(widths = c(3,NA),
  list(filter_select("window", "Window", sd, ~window),
  filter_select("Label_Target", "Reference", sd, ~Label_Target),
  filter_select("Revue", "Journal", sd, ~Revue),
  filter_slider("nb_cit","Share over total references", sd, ~nb_cit)),
  datatable(sd, extensions="Scroller", width="100%", class = "compact",
            options=list(deferRender=TRUE, scrollY=500, scroller=TRUE))
)
```

tf-idf by window{.tabset .tabset-pill .tabset-fade data-height=700}
----------------------------------

```{r tfidf-window, eval = TRUE, results = "asis"}

tf_idf_window <- readRDS(paste0(data_path, "EER/2_Raw_Networks_and_Alluv/tf_idf_windows.rds"))

for(i in unique(tf_idf_window$list_words[order(Community_name)]$Community_name)){
  cat(sprintf("  \n### %s \n\n", i))
  cat('\n', '<br>', '\n\n')
  plot(ggplot(tf_idf_window$list_words[Community_name == i], aes(reorder_within(word, tf_idf, color), tf_idf, fill = color)) +
    geom_bar(stat = "identity", alpha = .8, show.legend = FALSE) +
    labs(
      title = "Highest tf-idf",
      x = "Words", y = "tf-idf"
    ) +
    scale_fill_identity() +
    scale_x_reordered() +
    coord_flip() +
    theme_minimal())
  
  cat("  \n")
 
}

```


# Information on communities

Summary per communities {.tabset .tabset-pill .tabset-fade data-height=700}
-------------------------------------

### Top references per community

```{r manip_alluv, eval = TRUE}
# adding first and last years of each community in alluv_dt

com_years <- alluv_dt %>% 
  select(Leiden1, Window) %>% 
  group_by(Leiden1) %>% 
  mutate(Window = as.numeric(Window),
         first_year = min(Window),
         last_year = max(Window) + time_window - 1,
         com_years = paste0(first_year,"-",last_year)) %>% 
  select(Leiden1, com_years) %>% 
  unique()

alluv_dt <- alluv_dt %>% 
  inner_join(com_years)

```


```{r refs-per-community, eval = TRUE}
refs_com <- merge(unique(alluv_dt[,-"Window"]), Refs[ItemID_Ref_Target != "Null" & ItemID_Ref_Target != 0], by = "Id", allow.cartesian = TRUE)

# list titles for each itemID_Ref to merge later
titles <- refs_com %>% 
  select(ItemID_Ref_Target, Titre) %>% 
  filter(! is.na(Titre)) %>% 
  unique() %>% 
  group_by(ItemID_Ref_Target) %>% 
  slice(1)
  

refs_com <- refs_com[, `:=` (nb_ref = length(Refs[ItemID_Ref != "Null"]$ItemID_Ref_Target %>% unique()), nb_art = length(unique(alluv_dt$Id)))] %>% 
  .[, total_freq := .N/nb_ref, by = "ItemID_Ref_Target"] %>% 
  .[, nb_ref_com := .N, by = "Leiden1"] %>% 
  .[, com_freq := .N/nb_ref_com, by = c("Leiden1","ItemID_Ref_Target")] %>% 
  .[, norm_dev_ref := round(sqrt(nb_art)*(com_freq - total_freq)/sqrt(total_freq*(1-total_freq)),3)] %>% 
  .[order(-norm_dev_ref), head(.SD, 1), .(ItemID_Ref_Target)]
  

top_refs <- refs_com %>% 
  select(Leiden1, com_years, ItemID_Ref_Target, Nom, Annee, Titre, Revue, norm_dev_ref) %>% 
  unique() %>% 
  group_by(Leiden1) %>% 
  slice_max(norm_dev_ref, n = 10) %>% 
  mutate(Label_Target = paste0(str_remove(str_extract(Nom,".*-"), "-"),
                               "-",
                               Annee,
                               "-",
                               str_extract(Titre, "[A-z]{4,}"))) %>% 
  select(-Titre)

top_refs <- merge(top_refs, titles, by = "ItemID_Ref_Target", all.x = TRUE)

# manage NA
na_title <- top_refs %>% 
  filter(is.na(Titre))

top_refs <- top_refs %>% 
  filter(! is.na(Titre))

na_title <- na_title %>% 
  filter(! ItemID_Ref_Target %in% top_refs$ItemID_Ref_Target)

top_refs <- rbind(top_refs, na_title) %>% 
  arrange(Leiden1) %>% 
  select(-ItemID_Ref_Target) %>% 
  relocate(Titre, .after = Annee)

# Wrap data frame in SharedData
sd <- SharedData$new(top_refs)

# Create a filter input
bscols(widths = c(3,NA),
  list(filter_select("Leiden1", "Community Name", sd, ~Leiden1),
  filter_select("Label_Target", "Reference", sd, ~Label_Target),
  filter_select("Revue", "Journal", sd, ~Revue),
  filter_slider("norm_dev_ref","Normal Deviation Measure", sd, ~norm_dev_ref)),
  datatable(sd, extensions="Scroller", width="100%", class = "compact",
            options=list(deferRender=TRUE, scrollY=500, scroller=TRUE))
)



```

### Top nodes per community

```{r nodes-per-community, eval = TRUE}
nodes_com <- merge(unique(alluv_dt[,-"Window"]), Corpus, by.x = "Id", by.y = "ID_Art", allow.cartesian = TRUE)

nodes_com <- merge(nodes_com,
                    unique(refs_com[ItemID_Ref %in% nodes_com$ItemID_Ref, c("Leiden1","ItemID_Ref", "norm_dev_ref")]),
                    by = c("Leiden1","ItemID_Ref"),
                    all.x = TRUE) %>% 
  mutate(norm_dev_ref = replace(norm_dev_ref, is.na(norm_dev_ref), 0))


top_nodes <- nodes_com %>% 
  select(Leiden1, com_years, Nom_ISI, Annee_Bibliographique, Titre, norm_dev_ref) %>% 
  unique() %>% 
  group_by(Leiden1) %>% 
  slice_max(norm_dev_ref, n = 10) %>% 
  mutate(Label_Target = paste0(str_remove(str_extract(Nom_ISI,".*-"), "-"),
                               "-",
                               Annee_Bibliographique,
                               "-",
                               str_extract(Titre, "[A-z]{4,}"))) %>% 
  filter(norm_dev_ref > 0)

# Wrap data frame in SharedData
sd <- SharedData$new(top_nodes)

# Create a filter input
bscols(widths = c(3,NA),
  list(filter_select("Leiden1", "Community Name", sd, ~Leiden1),
  filter_select("Label_Target", "Reference", sd, ~Label_Target),
  filter_slider("norm_dev_ref","Normal Deviation Measure", sd, ~norm_dev_ref)),
  datatable(sd, extensions="Scroller", width="100%", class = "compact",
            options=list(deferRender=TRUE, scrollY=500, scroller=TRUE))
)



```

tf-idf by communities{.tabset .tabset-pill .tabset-fade data-height=700}
----------------------------------

```{r tfidf-community, eval = TRUE, results = "asis"}

tf_idf_com <- readRDS(paste0(data_path, "EER/2_Raw_Networks_and_Alluv/tf_idf_communities.rds"))

for(i in unique(tf_idf_com$list_words[order(Community_name)]$Community_name)){
  cat(sprintf("  \n### %s \n\n", i))
  cat('\n', '<br>', '\n\n')
  plot(ggplot(tf_idf_com$list_words[Community_name == i], aes(reorder_within(word, tf_idf, color), tf_idf, fill = color)) +
    geom_bar(stat = "identity", alpha = .8, show.legend = FALSE) +
    labs(
      title = "Highest tf-idf",
      x = "Words", y = "tf-idf"
    ) +
    scale_fill_identity() +
    scale_x_reordered() +
    coord_flip() +
    theme_minimal())
  
  cat("  \n")
 
}

```


# Analysis of macro articles

Graphs of macro articles {.tabset .tabset-pill .tabset-fade data-height=700}
-------------------------------------

### Most recurrent affiliations

```{r top_inst_macro, eval = TRUE, include = TRUE, fig.height= 12}

institutions_macro <- merge(institutions, Corpus[JEL_id == 1, "ID_Art"], by = "ID_Art")

big_inst_year <- institutions_macro[, `:=` (n = .N), by = "Annee_Bibliographique"] %>% 
  .[Institution != "NULL", frequency := round(.N/n,2), by = c("Annee_Bibliographique","Institution")] %>% 
  select(Institution,Annee_Bibliographique,frequency,Type) %>% 
  filter(Annee_Bibliographique > 1971) %>% # We have some missing data for 1970 and 1971 for now
  mutate(Annee_Bibliographique = as.numeric(Annee_Bibliographique)) %>%  # useful for plotting later
  unique()

big_inst <- big_inst_year %>% 
  group_by(Annee_Bibliographique) %>% 
  arrange(Annee_Bibliographique,desc(frequency)) %>% 
  slice_max(frequency, n = 1) %>% 
  select(Institution) %>% 
  unique()

big_inst_year <- big_inst_year %>% 
  filter(Institution %in% big_inst$Institution)

ref_table <- data.table("Institution" = rep(unique(big_inst_year$Institution), length(1971:2019)), "Annee_Bibliographique" = rep(1971:2019, each = length(unique(big_inst_year$Institution))))
big_inst_year <- merge(big_inst_year, ref_table, by = c("Institution","Annee_Bibliographique"), all.y = TRUE) %>% 
  mutate(frequency = replace(frequency, is.na(frequency), 0))
big_inst_year <- merge(big_inst_year[,c("Institution","Annee_Bibliographique","frequency")], unique(big_inst_year[!is.na(Type),c("Institution","Type")]), by = "Institution", all.x = TRUE)

big_inst_year <- highlight_key(big_inst_year, ~Type)
#type_filter <- filter_select(
#  "Type", "Type of Institution", 
#  big_inst_year, ~Type
#)

x <- ggplot(big_inst_year, aes(Annee_Bibliographique, frequency, color = Institution)) +
#  geom_point() +
  geom_smooth(se = FALSE, span = 0.3, size = 1.5, alpha = 0.6) +
  scale_color_scico_d(palette = "roma") +
  dark_theme_classic()

#bscols(type_filter, highlight(ggplotly(x), "plotly_click"), widths = c(6,6))

type_inst <- institutions_macro[, `:=` (n = .N), by = "Annee_Bibliographique"] %>% 
  .[Institution != "NULL", frequency := round(.N/n,2), by = c("Annee_Bibliographique","Type")] %>% 
  select(Annee_Bibliographique,frequency,Type) %>% 
  filter(Annee_Bibliographique > 1971 & !is.na(Type) & Type != "NA") %>% # We have some missing data for 1970 and 1971 for now
  mutate(Annee_Bibliographique = as.numeric(Annee_Bibliographique)) %>%  # useful for plotting later
  unique()

ref_table <- data.table("Type" = rep(unique(type_inst$Type), length(1971:2019)), "Annee_Bibliographique" = rep(1971:2019, each = length(unique(type_inst$Type))))
type_inst <- merge(type_inst, ref_table, by = c("Type","Annee_Bibliographique"), all.y = TRUE) %>% 
  mutate(frequency = replace(frequency, is.na(frequency), 0))

type_inst <- highlight_key(type_inst, ~Type)

y <- ggplot(type_inst, aes(Annee_Bibliographique, frequency, color = Type)) +
#  geom_point() +
  geom_smooth(se = FALSE, span = 0.3, size = 1.5, alpha = 0.6, show.legend = FALSE) +
  scale_color_scico_d(palette = "vik", begin = 0.1) +
  dark_theme_classic()

#ggplotly(y)

subplot(style(highlight(ggplotly(y), "plotly_click"), showlegend = FALSE),highlight(ggplotly(x), "plotly_click"), nrows = 2)
```

### Authors' country affiliation

```{r top_country-macro, eval = TRUE}
# We calculate here the share of authors for the biggest countries

count_year <- institutions_macro[,n_inst_tot:=.N, Pays][order(-n_inst_tot)]
count_year <- count_year[n_inst_tot<50, Pays:="OTHER"]
count_year <- count_year[, nb_aut_country:=.N, .(Annee_Bibliographique, Pays)]
count_year <- count_year %>% 
  mutate(Annee_Bibliographique = as.numeric(Annee_Bibliographique),
         Pays = fct_rev(fct_infreq(Pays)))

count_year <- highlight_key(count_year, ~Countries_grouped)
x <- ggplot(count_year, aes(Annee_Bibliographique, after_stat(count), fill = Pays)) +
  geom_density(position = "fill") +
  labs(fill = "Countries (Top 7)") +
  scale_x_continuous("Years") +
  scale_y_continuous("Countries Identified by Unique Institution by Paper") +
  scale_fill_scico_d(palette = "hawaii", end = 1, direction = 1) +
  dark_theme_classic()

# We calculate here the share of authors for different grouped countries (EUROPE, USA and OTHER)
count_year_group <- institutions_macro[,n_inst_tot:=.N, Countries_grouped][order(-n_inst_tot)]
count_year_group <- count_year_group[n_inst_tot<100, Countries_grouped:="OTHER"]
count_year_group <- count_year_group[, nb_aut_country:=.N, .(Annee_Bibliographique, Countries_grouped)]
count_year_group <- count_year_group %>% 
  mutate(Annee_Bibliographique = as.numeric(Annee_Bibliographique),
         Countries_grouped = fct_rev(fct_infreq(Countries_grouped)))

count_year_group <- highlight_key(count_year_group, ~Countries_grouped)
y <- ggplot(count_year_group, aes(Annee_Bibliographique, after_stat(count), fill = Countries_grouped)) +
  geom_density(position = "fill") +
  labs(fill = "Countries (Grouped)") +
  scale_x_continuous("Years") +
  scale_y_continuous("Countries Identified by Unique Institution by Paper") +
  scale_fill_scico_d(palette = "lapaz", end = 0.9, direction = -1) +
  dark_theme_classic()

subplot(highlight(ggplotly(y), "plotly_click"),highlight(ggplotly(x), "plotly_click"))

```

### Most cited references

```{r references-macro, eval = TRUE}
authors_macro <- merge(Authors, Corpus[JEL_id == 1, "ID_Art"], by = "ID_Art")
top_auth <- authors_macro[,.N,Nom_ISI] %>% slice_max(order_by = N, n = 20)

refs_macro <- merge(Refs, Corpus[JEL_id == 1, "ID_Art"], by = "ID_Art")
top_ref <- copy(refs_macro[! ItemID_Ref_Target %in% c("NULL","0"), nb_cit := .N, by = "ItemID_Ref_Target"][order(-nb_cit,Titre), head(.SD, 1), .(ItemID_Ref_Target)][,.(Nom, Titre, Annee_Bibliographique_Target, nb_cit, ItemID_Ref_Target)]%>% slice_max(order_by = nb_cit, n = 20))

top_ref_alt <- merge(refs_macro[! ItemID_Ref_Target %in% c("NULL","0")], Corpus[, c("ID_Art","Annee_Bibliographique")], by.x = "ID_Art_Source", by.y = "ID_Art") 
top_ref_alt <- top_ref_alt[, nb_cit_year := .N, by = "Annee_Bibliographique"][,nb_cit_year := 1/nb_cit_year][, nb_cit_weighted := sum(nb_cit_year), by = "ItemID_Ref_Target"]
top_ref_alt <- top_ref_alt[order(-nb_cit_weighted, Titre), head(.SD, 1), .(ItemID_Ref_Target)][,.(Nom, Titre, Annee_Bibliographique_Target,nb_cit_weighted, ItemID_Ref_Target)] %>% 
  slice_max(order_by = nb_cit_weighted, n = 20)

top_ref <- merge(top_ref, top_ref_alt, by = "ItemID_Ref_Target", all = TRUE)
top_ref[is.na(Nom.x)]$Nom.x <- top_ref[is.na(Nom.x)]$Nom.y
top_ref[is.na(Titre.x)]$Titre.x <- top_ref[is.na(Titre.x)]$Titre.y
top_ref[is.na(Annee_Bibliographique_Target.x)]$Annee_Bibliographique_Target.x <- top_ref[is.na(Annee_Bibliographique_Target.x)]$Annee_Bibliographique_Target.y
setnames(top_ref, c("Nom.x","Annee_Bibliographique_Target.x", "Titre.x"), c("Nom","Annee_Bibliographique","Titre"))

bscols(widths = c(4,8),
       datatable(top_auth, extensions="Scroller", width="100%", class = "compact",
            options=list(deferRender=TRUE, scrollY=500, scroller=TRUE)),
       datatable(top_ref[, c("Nom","Annee_Bibliographique","Titre","nb_cit","nb_cit_weighted")], extensions="Scroller", width="100%", class = "compact",
            options=list(deferRender=TRUE, scrollY=500, scroller=TRUE))
)

```


### Important macro refs over time

```{r refs_macro,eval=TRUE}
ref_over_time <- merge(unique(nodes_lf[window >= 1974 ,c("ID_Art","window")]), refs_macro[,c("ID_Art_Source","ItemID_Ref_Target","Label_Target","Titre","Revue")], by.x = "ID_Art", by.y = "ID_Art_Source", allow.cartesian = TRUE)
#ref_over_time <- merge(ref_over_time, unique(Corpus[JEL_id == 1,c("ID_Art")]), by = "ID_Art")

ref_over_time <- ref_over_time[, nb_ref := .N, by = "window"] %>% 
  .[, nb_cit := round((.N/nb_ref)*100,3), by = c("window","ItemID_Ref_Target")] %>% 
  .[, -"ID_Art"] %>% 
  .[order(window,nb_cit)] %>% 
  .[, head(.SD,1), by = c("window","ItemID_Ref_Target")]

top_ref <- ref_over_time %>% 
  filter(! ItemID_Ref_Target %in% c("NULL", "0")) %>%
  group_by(window) %>% 
  slice_max(nb_cit, n = 3, with_ties = TRUE) %>% 
  ungroup() %>% 
  select(-window, -nb_cit, -nb_ref) %>% 
  unique()

ref_over_time <- ref_over_time[ItemID_Ref_Target %in% top_ref$ItemID_Ref_Target] %>% 
  complete(ItemID_Ref_Target, window, fill = list(nb_cit = 0)) %>% 
  select(ItemID_Ref_Target, window, nb_cit) %>% 
  left_join(top_ref)

# for later
setnames(top_ref, "ItemID_Ref_Target", "ItemID_Ref")
setnames(ref_over_time, "ItemID_Ref_Target", "ItemID_Ref")

# changing labels for doublons
doublons <- unique(ref_over_time[,c("ItemID_Ref","Label_Target")]) %>% 
  group_by(Label_Target) %>% 
  mutate(total = n()) %>% 
  filter(total == 2) %>% 
  mutate(Label_Target = c("BARRO,1983a","BARRO,1983b"))

# merging new names
ref_over_time <- merge(ref_over_time, doublons, by = "ItemID_Ref", all.x = TRUE) %>% 
  as.data.table()
ref_over_time[!is.na(Label_Target.y)]$Label_Target.x <- ref_over_time[!is.na(Label_Target.y)]$Label_Target.y
setnames(ref_over_time, "Label_Target.x", "Label_Target")
ref_over_time <- ref_over_time[, -c("Label_Target.y","total")]



# projecting
sd <- highlight_key(ref_over_time, ~Label_Target)
plot_ly(sd, 
        text = ~paste('</br>', Label_Target,
                      '</br>', str_wrap(Titre, width = 30),
                      '</br>', Revue,
                      '</br>', paste0(window,"-",as.integer(window) + (time_window-1))),
        hoverinfo = "text") %>% 
  add_lines(x = ~window, 
            y = ~nb_cit, 
            color = ~Label_Target) %>% 
  add_trace(alpha = 0.8) %>% 
  layout(paper_bgcolor = "black",
         plot_bgcolor = "black") %>% 
  config(scrollZoom = TRUE) %>% 
  highlight(on = "plotly_click",
            persistent = TRUE,
            selectize = TRUE)

```

### Most recurrent words

```{r words-macro, eval = TRUE}
words_over_time <- merge(alluv_with_abstract, Corpus[JEL_id == 1, "Id"], by = "Id") %>%
  select(Id, Window, words) %>% 
  unique() %>% 
  unnest_tokens(word, words) %>% 
  anti_join(stop_words) %>% 
  as.data.table()

words_over_time <- words_over_time[, word := textstem::lemmatize_words(word)] %>% 
  .[, total_window := .N, by = "Window"] %>% 
  .[, proportion := round(.N/total_window,5), by = c("Window","word")] %>% 
  .[, -"Id"] %>% 
  .[order(Window,-proportion)]%>% 
  .[, head(.SD,1), by = c("Window","word")]

too_common_words <- c("economy",
                      "model",
                      "result",
                      "paper",
                      "country",
                      "price",
                      "function",
                      "effect",
                      "rate",
                      "increase",
                      "datum",
                      "evidence",
                      "level",
                      "study",
                      "traditional",
                      "macroeconomic",
                      "assume",
                      "introduce",
                      "explicitly",
                      "logical",
                      "show",
                      "substantially",
                      "aggregate",
                      "run",
                      "simple",
                      "sector",
                      "standard")
words_over_time <- words_over_time[! word %in% too_common_words]
  
top_word <- words_over_time %>% 
  group_by(Window) %>% 
  slice_max(proportion, n = 4, with_ties = TRUE) %>% 
  ungroup() %>% 
  select(-Window, -total_window, -proportion) %>% 
  unique()

words_over_time <- words_over_time[word %in% top_word$word] %>% 
  complete(word, Window, fill = list(proportion = 0)) %>% 
  select(word, Window, proportion) %>% 
  left_join(top_word)

plot_ly(words_over_time, 
        text = ~word,
        hoverinfo = "text") %>% 
  add_lines(x = ~Window, 
        y = ~proportion,
        color = ~word) %>% 
  add_trace(alpha = 0.8) %>% 
  layout(paper_bgcolor = "black",
         plot_bgcolor = "black") %>% 
  config(scrollZoom = TRUE)

```

### Most recurrent bigrams

```{r bigrams-macro, eval = TRUE}
bigrams_over_time <- merge(alluv_with_abstract, Corpus[JEL_id == 1, "Id"], by = "Id") %>%
  select(Id, Window, words) %>% 
  unique() %>% 
  unnest_tokens(bigram, words, token = "ngrams", n = 2) %>% 
  separate(bigram, c("word1", "word2"), sep = " ") %>% 
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word) %>% 
  mutate(word1 = textstem::lemmatize_words(word1),
         word2 = textstem::lemmatize_words(word2)) %>% 
  unite(bigram, word1, word2, sep = " ") %>% 
  as.data.table()

bigrams_over_time <- bigrams_over_time[, total_window := .N, by = "Window"] %>% 
  .[, proportion := round(.N/total_window,5), by = c("Window","bigram")] %>% 
  .[, -"Id"] %>% 
  .[order(Window,-proportion)]%>% 
  .[, head(.SD,1), by = c("Window","bigram")]

too_common_words <- c("explicitly introduced",
                      "paper real",
                      "logical consequence",
                      "standard specifications",
                      "traditional results")
bigrams_over_time <- bigrams_over_time[! bigram %in% too_common_words]
  
top_bigram <- bigrams_over_time %>% 
  group_by(Window) %>% 
  slice_max(proportion, n = 3, with_ties = TRUE) %>% 
  ungroup() %>% 
  select(-Window, -total_window, -proportion) %>% 
  unique()

bigrams_over_time <- bigrams_over_time[bigram %in% top_bigram$bigram] %>% 
  complete(bigram, Window, fill = list(proportion = 0)) %>% 
  select(bigram, Window, proportion) %>% 
  left_join(top_bigram)

plot_ly(bigrams_over_time, 
        text = ~bigram,
        hoverinfo = "text") %>% 
  add_lines(x = ~Window, 
        y = ~proportion,
        color = ~bigram) %>% 
  add_trace(alpha = 0.8) %>% 
  layout(paper_bgcolor = "black",
         plot_bgcolor = "black") %>% 
  config(scrollZoom = TRUE)

```

Comparison EER/JEL{.tabset .tabset-pill .tabset-fade data-height=700}
-------------------------------------

### Comparing all macro articles refs with EER

```{r chi-2, eval = TRUE}
# creating the time window
nodes_JEL_window <- data.table("ID_Art" = c(), "window" = c())

for(Year in 1974:2010){
nodes <- nodes_JEL[between(Annee_Bibliographique,Year, Year + (time_window-1))]
nodes <- nodes[,window := paste0(Year, "-", Year + (time_window-1))][,c("ID_Art","window")]
nodes_JEL_window <- rbind(nodes_JEL_window,nodes)
}

nodes_JEL_window <- merge(nodes_JEL_window, edges_JEL[ItemID_Ref != 0], by = "ID_Art", allow.cartesian = TRUE)

# Calculating citation for macro JEL
nodes_JEL_window <- nodes_JEL_window[, nb_ref := .N, by = "window"] %>% 
  .[, nb_cit := .N, by = c("window","ItemID_Ref")] %>% 
  .[, -"ID_Art"] %>% 
  .[order(window,-nb_cit)] %>% 
  .[, head(.SD,1), by = c("window","ItemID_Ref")]

top_ref_JEL <- nodes_JEL_window %>% 
  group_by(window) %>% 
  slice_max(nb_cit, n = 3, with_ties = TRUE) %>% 
  ungroup() %>% 
  select(-window, -nb_cit, -nb_ref, -New_id2, -Revue_Abbrege) %>% 
  mutate(Label_Target = paste0(str_remove(Nom, "-.*"),",",Annee)) %>% 
  unique()


# merging with the most cited ref for EER
top_ref_JEL <- rbind(top_ref[,c("ItemID_Ref","Label_Target")],top_ref_JEL[,c("ItemID_Ref","Label_Target")]) %>% 
  mutate(ItemID_Ref = as.character(ItemID_Ref)) %>% 
  unique()

nodes_JEL_window$ItemID_Ref <- as.character(nodes_JEL_window$ItemID_Ref)
nodes_JEL_window <- nodes_JEL_window[ItemID_Ref %in% top_ref_JEL$ItemID_Ref] %>% 
  complete(ItemID_Ref, window, fill = list(nb_cit = 0)) %>% 
  select(ItemID_Ref, window, nb_cit, nb_ref) %>% 
  left_join(top_ref_JEL)

# recalculating the number of citations by EER of EER and JEL most cited refs
ref_over_time <- merge(unique(nodes_lf[between(window, 1974, 2010),c("ID_Art","window")]), refs_macro[,c("ID_Art_Source","ItemID_Ref_Target","Label_Target","Titre","Revue")], by.x = "ID_Art", by.y = "ID_Art_Source", allow.cartesian = TRUE)

ref_over_time <- ref_over_time[, nb_ref := .N, by = "window"] %>% 
  .[, nb_cit := .N, by = c("window","ItemID_Ref_Target")] %>% 
  .[, -"ID_Art"] %>% 
  .[order(window,nb_cit)] %>% 
  .[, head(.SD,1), by = c("window","ItemID_Ref_Target")]

ref_over_time <- ref_over_time[ItemID_Ref_Target %in% top_ref_JEL$ItemID_Ref] %>% 
  complete(ItemID_Ref_Target, window, fill = list(nb_cit = 0)) %>% 
  select(ItemID_Ref_Target, window, nb_cit, nb_ref) %>% 
  rename("ItemID_Ref" = ItemID_Ref_Target) %>% 
  left_join(top_ref_JEL) %>% 
  mutate(window = paste0(window,"-", as.integer(window) + (time_window - 1)))

# merging the two corpora
corpus_comparison <- merge(nodes_JEL_window, ref_over_time[, c("ItemID_Ref","window","nb_cit","nb_ref")], by = c("ItemID_Ref","window"))
setnames(corpus_comparison, c("nb_cit.x","nb_cit.y","nb_ref.x","nb_ref.y"), c("nb_cit_JEL","nb_cit_EER","nb_ref_JEL","nb_ref_EER"))

# changing labels for doublons
doublons <- unique(corpus_comparison[,c("ItemID_Ref","Label_Target")]) %>% 
  group_by(Label_Target) %>% 
  mutate(total = n()) %>% 
  filter(total == 2) %>% 
  mutate(Label_Target = c("BARRO,1983a","BARRO,1983b"))

# merging new names
corpus_comparison <- merge(corpus_comparison, doublons, by = "ItemID_Ref", all.x = TRUE) %>% 
  as.data.table()
corpus_comparison[!is.na(Label_Target.y)]$Label_Target.x <- corpus_comparison[!is.na(Label_Target.y)]$Label_Target.y
setnames(corpus_comparison, "Label_Target.x", "Label_Target")
corpus_comparison <- corpus_comparison[, -c("Label_Target.y","total")]

# adding missing nb_of refs
missing_nb_ref <- corpus_comparison %>% 
  select(window, nb_ref_EER, nb_ref_JEL) %>% 
  filter(!is.na(nb_ref_EER), !is.na(nb_ref_JEL)) %>% 
  unique() %>% 
  arrange(window)

for(i in missing_nb_ref$window){
  corpus_comparison[window == i]$nb_ref_EER <- missing_nb_ref[window == i]$nb_ref_EER
  corpus_comparison[window == i]$nb_ref_JEL <- missing_nb_ref[window == i]$nb_ref_JEL
}

# calculating respective shares
corpus_comparison[, `:=` (share_cit_EER = nb_cit_EER/nb_ref_EER, share_cit_JEL = nb_cit_JEL / nb_ref_JEL)]

# We delete the lines for references not published for some window
corpus_comparison <- corpus_comparison %>% 
  mutate(year = str_extract(Label_Target, "[:digit:]{4}"),
         window_end = str_extract(window, "[:digit:]{4}$")) %>% 
  filter(year < window_end)

res_chi_corpus <- data.frame(Year = c(), ItemID_Ref = c(), Res_chi = c())

for(i in corpus_comparison$window){
  res_chi <- chisq.test(corpus_comparison[window == i, list(share_cit_JEL, share_cit_EER)])
  
  res_chi_partial <- corpus_comparison[window == i, c("window","ItemID_Ref")]
  res_chi_partial$Res_chi <- res_chi$residuals[,2]
  
  res_chi_corpus <- rbind(res_chi_corpus, res_chi_partial)
}

corpus_comparison <- merge(corpus_comparison, unique(res_chi_corpus), by = c("window","ItemID_Ref"))

# projecting
sd <- highlight_key(corpus_comparison, ~Label_Target)
plot_ly(sd, 
        text = ~paste('</br>', Label_Target,
                      '</br>', window),
        hoverinfo = "text") %>% 
  add_lines(x = ~window, 
            y = ~Res_chi, 
            color = ~Label_Target) %>% 
  add_trace(alpha = 0.8) %>% 
  layout(paper_bgcolor = "black",
         plot_bgcolor = "black") %>% 
  config(scrollZoom = TRUE) %>% 
  highlight(on = "plotly_click",
            persistent = TRUE,
            selectize = TRUE)
```


```{r sigma-projection, eval = FALSE, results='asis', include= TRUE}
# NOT WORKING: the chunk is working but the results are not projected (even if projected if we do it one by one)

color_com <- data.table("Leiden1" = levels(nodes$Leiden1),
                        "color" = color)
nodes <- merge(nodes, color_com, by = "Leiden1")
setnames(nodes, c("ID_Art","Label"),
         c("id","label"))

edges <- lapply(list_graph, function(tbl) (tbl %>% activate(edges) %>% as.data.table()))
edges <- lapply(edges, function(dt) (dt[, .(Source,Target,weight)]))
edges <- rbindlist(edges, idcol = "window") %>% 
  .[, `:=` (id = 1:.N, window = paste0(window, "-", as.integer(window) + (time_window-1)))] %>% 
  .[window %in% nodes$window[1:3]]
setnames(edges, c("Source","Target","weight"),c("source","target","size"))

# every identifier in character format for projection
nodes$id <- as.character(nodes$id)
edges$source <- as.character(edges$source)
edges$target <- as.character(edges$target)
edges$id <- as.character(edges$id)

windows <- unique(nodes[order(window)]$window)[1]

for(i in seq_along(windows)){
 # cat(sprintf("  \n### Network %s \n\n", unique(nodes$window)[i]))
#  cat('\n', '<br>', '\n\n')
  
x <- sigmajs() %>% # initialise
      sg_nodes(nodes[window == nodes$window[i]], id, label, size, color, x, y) %>% # add nodes
      sg_edges(edges[window == nodes$window[i]], id, source, target, size) %>% # add edges
      sg_settings(drawLabels = FALSE, drawEdgeLabels = FALSE, 
                 defaultEdgeType = "curve", minNodeSize = 2, maxNodeSize = 8, 
                minEdgeSize = 0.5, maxEdgeSize = 3,
                 borderSize = 0.5, labelHoverBGColor = "node", singleHover = TRUE,
                 hideEdgesOnMove = TRUE, zoomMin = 0.4, zoomMax = 1.2) %>% 
      sg_neighbors()

saveWidget(x, paste0(picture_path,"graph_", windows[i],".html"), selfcontained = TRUE)

}
```   


```{r sigma-plot, eval = FALSE, results='asis', include= TRUE}
cat(paste0("<iframe\nsrc=\"/home/aurelien/macro_AA/EER_Paper/Pictures/graph_1969-1975.html\"\nwidth=\"100%\"\nheight=\"500px\">\n</iframe>"), "\n")
```
